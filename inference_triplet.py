import os
import json
import torch
import argparse
from transformers import AutoTokenizer, AutoModel
from glm_config import ProjectConfig
import peft

pc = ProjectConfig()

class TripletExtractor:
    def __init__(self, model_path=None):
        """
        åˆå§‹åŒ–ä¸‰å…ƒç»„æŠ½å–å™¨
        
        Args:
            model_path (str): å¾®è°ƒåçš„æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„æœ€ä½³æ¨¡å‹è·¯å¾„
        """
        self.model_path = model_path or os.path.join(pc.save_dir, "model_best")
        self.device = pc.device
        self.tokenizer = None
        self.model = None
        
    def load_model(self):
        """åŠ è½½æ¨¡å‹å’Œtokenizer"""
        print(f"ğŸ¤– åŠ è½½æ¨¡å‹ä»: {self.model_path}")
        
        # åŠ è½½tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_path, 
            trust_remote_code=True
        )
        
        # åŠ è½½æ¨¡å‹
        self.model = AutoModel.from_pretrained(
            self.model_path,
            trust_remote_code=True,
            torch_dtype=torch.float16 if pc.fp16 else torch.float32
        ).to(self.device)
        
        self.model.eval()
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        
    def create_prompt(self, text: str) -> str:
        """
        åˆ›å»ºä¸‰å…ƒç»„æŠ½å–çš„æç¤ºè¯
        
        Args:
            text (str): è¾“å…¥æ–‡æœ¬
            
        Returns:
            str: æ ¼å¼åŒ–çš„æç¤ºè¯
        """
        prompt = f"""Instruction: ä½ ç°åœ¨æ˜¯ä¸€ä¸ªå¾ˆå‰å®³çš„é˜…è¯»ç†è§£å™¨ï¼Œä¸¥æ ¼æŒ‰ç…§äººç±»æŒ‡ä»¤è¿›è¡Œå›ç­”ã€‚
Input: å¸®æˆ‘æŠ½å–å‡ºä¸‹é¢å¥å­ä¸­çš„ä¸‰å…ƒç»„ä¿¡æ¯ï¼Œè¿”å›JSONï¼š

{text}
Answer: """
        return prompt
        
    def extract_triplets(self, text: str, max_length: int = 512, temperature: float = 0.1) -> str:
        """
        ä»æ–‡æœ¬ä¸­æŠ½å–ä¸‰å…ƒç»„
        
        Args:
            text (str): è¾“å…¥æ–‡æœ¬
            max_length (int): ç”Ÿæˆçš„æœ€å¤§é•¿åº¦
            temperature (float): ç”Ÿæˆæ¸©åº¦ï¼Œè¶Šä½è¶Šç¡®å®šæ€§
            
        Returns:
            str: ç”Ÿæˆçš„ä¸‰å…ƒç»„JSONå­—ç¬¦ä¸²
        """
        if self.model is None or self.tokenizer is None:
            self.load_model()
            
        prompt = self.create_prompt(text)
        
        # ç¼–ç è¾“å…¥
        inputs = self.tokenizer.encode(prompt, return_tensors="pt").to(self.device)
        
        # ç”Ÿæˆå›ç­”
        with torch.no_grad():
            outputs = self.model.generate(
                inputs,
                max_length=len(inputs[0]) + max_length,
                temperature=temperature,
                do_sample=True if temperature > 0 else False,
                top_p=0.9,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id
            )
        
        # è§£ç è¾“å‡º
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # æå–ç­”æ¡ˆéƒ¨åˆ†
        if "Answer: " in response:
            answer = response.split("Answer: ")[-1].strip()
        else:
            answer = response
            
        return answer
    
    def parse_triplets(self, response: str) -> list:
        """
        è§£æç”Ÿæˆçš„ä¸‰å…ƒç»„JSON
        
        Args:
            response (str): æ¨¡å‹ç”Ÿæˆçš„å“åº”
            
        Returns:
            list: è§£æåçš„ä¸‰å…ƒç»„åˆ—è¡¨
        """
        try:
            # æŸ¥æ‰¾JSONä»£ç å—
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                json_str = response[json_start:json_end].strip()
            else:
                # å¦‚æœæ²¡æœ‰ä»£ç å—æ ‡è®°ï¼Œå°è¯•ç›´æ¥è§£æ
                json_str = response.strip()
                
            # è§£æJSON
            triplets = json.loads(json_str)
            return triplets if isinstance(triplets, list) else [triplets]
            
        except (json.JSONDecodeError, ValueError) as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            return []
    
    def extract_and_parse(self, text: str, **kwargs) -> list:
        """
        æŠ½å–å¹¶è§£æä¸‰å…ƒç»„ï¼ˆä¸€æ­¥åˆ°ä½ï¼‰
        
        Args:
            text (str): è¾“å…¥æ–‡æœ¬
            **kwargs: ä¼ é€’ç»™extract_tripletsçš„å‚æ•°
            
        Returns:
            list: ä¸‰å…ƒç»„åˆ—è¡¨
        """
        response = self.extract_triplets(text, **kwargs)
        return self.parse_triplets(response)


def main():
    parser = argparse.ArgumentParser(description="ChatGLM-6B ä¸‰å…ƒç»„æŠ½å–æ¨ç†")
    parser.add_argument("--model_path", type=str, default=None, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--text", type=str, default=None, help="è¦æŠ½å–ä¸‰å…ƒç»„çš„æ–‡æœ¬")
    parser.add_argument("--interactive", action="store_true", help="äº¤äº’å¼æ¨¡å¼")
    parser.add_argument("--temperature", type=float, default=0.1, help="ç”Ÿæˆæ¸©åº¦")
    parser.add_argument("--max_length", type=int, default=512, help="æœ€å¤§ç”Ÿæˆé•¿åº¦")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æŠ½å–å™¨
    extractor = TripletExtractor(args.model_path)
    
    if args.interactive:
        print("ğŸ¯ è¿›å…¥äº¤äº’å¼ä¸‰å…ƒç»„æŠ½å–æ¨¡å¼")
        print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("-" * 50)
        
        while True:
            text = input("\nè¯·è¾“å…¥è¦æŠ½å–ä¸‰å…ƒç»„çš„æ–‡æœ¬: ").strip()
            
            if text.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ å†è§!")
                break
                
            if not text:
                print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆæ–‡æœ¬")
                continue
                
            print("\nğŸ” æ­£åœ¨æŠ½å–ä¸‰å…ƒç»„...")
            try:
                triplets = extractor.extract_and_parse(
                    text, 
                    temperature=args.temperature,
                    max_length=args.max_length
                )
                
                if triplets:
                    print(f"\nâœ… æŠ½å–åˆ° {len(triplets)} ä¸ªä¸‰å…ƒç»„:")
                    for i, triplet in enumerate(triplets, 1):
                        print(f"{i}. ä¸»ä½“: {triplet.get('subject', 'N/A')}")
                        print(f"   å…³ç³»: {triplet.get('predicate', 'N/A')}")
                        print(f"   å®¢ä½“: {triplet.get('object', 'N/A')}")
                        print(f"   ä¸»ä½“ç±»å‹: {triplet.get('subject_type', 'N/A')}")
                        print(f"   å®¢ä½“ç±»å‹: {triplet.get('object_type', 'N/A')}")
                        print()
                else:
                    print("âŒ æœªèƒ½æŠ½å–åˆ°æœ‰æ•ˆä¸‰å…ƒç»„")
                    
            except Exception as e:
                print(f"âŒ æŠ½å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    
    elif args.text:
        print(f"ğŸ” æŠ½å–æ–‡æœ¬: {args.text}")
        extractor = TripletExtractor(args.model_path)
        
        try:
            triplets = extractor.extract_and_parse(
                args.text,
                temperature=args.temperature,
                max_length=args.max_length
            )
            
            print(f"\nâœ… æŠ½å–ç»“æœ:")
            print(json.dumps(triplets, ensure_ascii=False, indent=2))
            
        except Exception as e:
            print(f"âŒ æŠ½å–å¤±è´¥: {e}")
    
    else:
        # æ¼”ç¤ºæ¨¡å¼
        print("ğŸ¯ ChatGLM-6B ä¸‰å…ƒç»„æŠ½å–æ¼”ç¤º")
        
        demo_texts = [
            "ã€Šå¨˜å®¶çš„æ•…äº‹ç¬¬äºŒéƒ¨ã€‹æ˜¯å¼ ç²æ‰§å¯¼ï¼Œæ—åœ¨åŸ¹ã€ä½•èµ›é£ç­‰ä¸»æ¼”çš„ç”µè§†å‰§ã€‚",
            "çˆ±å¾·åÂ·å°¼ç§‘Â·åŸƒå°”å—è¿ªæ–¯ï¼ˆ1986-ï¼‰ï¼Œæ˜¯ä¸€ä½èº«é«˜åªæœ‰70å…¬åˆ†å“¥ä¼¦æ¯”äºšç”·å­ã€‚",
            "å—è¿¦å¸•å°”å·´ç‰¹å³°ï¼Œ8125ç±³ã€‚"
        ]
        
        for i, text in enumerate(demo_texts, 1):
            print(f"\nğŸ“ ç¤ºä¾‹ {i}: {text}")
            try:
                triplets = extractor.extract_and_parse(text)
                print(f"âœ… æŠ½å–ç»“æœ: {json.dumps(triplets, ensure_ascii=False, indent=2)}")
            except Exception as e:
                print(f"âŒ æŠ½å–å¤±è´¥: {e}")


if __name__ == "__main__":
    main()