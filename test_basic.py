#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ChatGLM-6B QLoRA ä¸‰å…ƒç»„æŠ½å–åŸºç¡€æµ‹è¯•è„šæœ¬
"""

import os
import sys
import json

def test_environment():
    """æµ‹è¯•è¿è¡Œç¯å¢ƒ"""
    print("ğŸ” æµ‹è¯•è¿è¡Œç¯å¢ƒ...")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    
    # æ£€æŸ¥PyTorch
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False
    
    # æ£€æŸ¥transformers
    try:
        import transformers
        print(f"Transformersç‰ˆæœ¬: {transformers.__version__}")
    except ImportError:
        print("âŒ Transformersæœªå®‰è£…")
        return False
    
    # æ£€æŸ¥peft
    try:
        import peft
        print(f"PEFTç‰ˆæœ¬: {peft.__version__}")
    except ImportError:
        print("âŒ PEFTæœªå®‰è£…")
        return False
    
    print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
    return True

def test_config():
    """æµ‹è¯•é…ç½®"""
    print("\nğŸ” æµ‹è¯•é…ç½®...")
    
    try:
        from glm_config import ProjectConfig
        pc = ProjectConfig()
        print(f"è®¾å¤‡: {pc.device}")
        print(f"é¢„è®­ç»ƒæ¨¡å‹: {pc.pre_model}")
        print(f"è®­ç»ƒæ•°æ®è·¯å¾„: {pc.train_path}")
        print(f"éªŒè¯æ•°æ®è·¯å¾„: {pc.dev_path}")
        print(f"è¾“å‡ºç›®å½•: {pc.save_dir}")
        print(f"æ‰¹æ¬¡å¤§å°: {pc.batch_size}")
        print(f"æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {pc.gradient_accumulation_steps}")
        print(f"æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {pc.batch_size * pc.gradient_accumulation_steps}")
        print(f"åºåˆ—é•¿åº¦: {pc.max_source_seq_len} + {pc.max_target_seq_len} = {pc.max_seq_length}")
        print(f"LoRA rank: {pc.lora_rank}")
        print(f"æ··åˆç²¾åº¦: {pc.fp16}")
        
        print("âœ… é…ç½®æ£€æŸ¥é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æ£€æŸ¥å¤±è´¥: {e}")
        return False

def test_data_format():
    """æµ‹è¯•æ•°æ®æ ¼å¼"""
    print("\nğŸ” æµ‹è¯•æ•°æ®æ ¼å¼...")
    
    try:
        from glm_config import ProjectConfig
        pc = ProjectConfig()
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(pc.train_path):
            print(f"âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {pc.train_path}")
            return False
        if not os.path.exists(pc.dev_path):
            print(f"âŒ éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {pc.dev_path}")
            return False
        
        # è¯»å–å‡ ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
        with open(pc.train_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()[:3]  # åªæµ‹è¯•å‰3ä¸ªæ ·æœ¬
        
        valid_count = 0
        for i, line in enumerate(lines):
            try:
                data = json.loads(line.strip())
                context = data.get('context', '')
                target = data.get('target', '')
                
                print(f"æ ·æœ¬ {i+1}:")
                print(f"  è¾“å…¥é•¿åº¦: {len(context)}")
                print(f"  è¾“å‡ºé•¿åº¦: {len(target)}")
                
                # ç®€å•éªŒè¯æ ¼å¼
                if context and target and 'json' in target:
                    valid_count += 1
                    print(f"  æ ¼å¼: âœ… æœ‰æ•ˆ")
                else:
                    print(f"  æ ¼å¼: âŒ æ— æ•ˆ")
                    
            except Exception as e:
                print(f"  è§£æå¤±è´¥: {e}")
        
        print(f"\næœ‰æ•ˆæ ·æœ¬: {valid_count}/{len(lines)}")
        
        if valid_count == 0:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ ·æœ¬")
            return False
        
        print("âœ… æ•°æ®æ ¼å¼æ£€æŸ¥é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ ¼å¼æ£€æŸ¥å¤±è´¥: {e}")
        return False

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("\nğŸ” æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        # æµ‹è¯•é…ç½®å¯¼å…¥
        from glm_config import ProjectConfig
        print("âœ… é…ç½®æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•å·¥å…·æ¨¡å—å¯¼å…¥
        from utils.common_utils import CastOutputToFloat, save_model
        print("âœ… å·¥å…·æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        print("âœ… æ¨¡å—å¯¼å…¥æ£€æŸ¥é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥æ£€æŸ¥å¤±è´¥: {e}")
        return False

def test_model_path():
    """æµ‹è¯•æ¨¡å‹è·¯å¾„"""
    print("\nğŸ¤– æµ‹è¯•æ¨¡å‹è·¯å¾„...")
    
    try:
        from glm_config import ProjectConfig
        pc = ProjectConfig()
        
        print(f"æ¨¡å‹è·¯å¾„: {pc.pre_model}")
        
        # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(pc.pre_model):
            print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {pc.pre_model}")
            print("ğŸ’¡ è¯·ç¡®è®¤:")
            print("   1. æ¨¡å‹å·²ä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„")
            print("   2. æˆ–ä¿®æ”¹ glm_config.py ä¸­çš„ self.pre_model è·¯å¾„")
            print("   3. æˆ–ä½¿ç”¨åœ¨çº¿æ¨¡å‹: 'THUDM/chatglm-6b'")
            return False
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        required_files = ['config.json']
        for file in required_files:
            file_path = os.path.join(pc.pre_model, file)
            if not os.path.exists(file_path):
                print(f"âŒ ç¼ºå°‘å…³é”®æ–‡ä»¶: {file}")
                return False
        
        print("âœ… æ¨¡å‹è·¯å¾„æ£€æŸ¥é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è·¯å¾„æ£€æŸ¥å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ ChatGLM-6B QLoRA ä¸‰å…ƒç»„æŠ½å–åŸºç¡€æµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("ç¯å¢ƒæ£€æŸ¥", test_environment),
        ("é…ç½®æ£€æŸ¥", test_config),
        ("æ¨¡å—å¯¼å…¥æ£€æŸ¥", test_imports),
        ("æ¨¡å‹è·¯å¾„æ£€æŸ¥", test_model_path),
        ("æ•°æ®æ ¼å¼æ£€æŸ¥", test_data_format),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            if test_func():
                passed += 1
                print(f"âœ… {test_name} é€šè¿‡")
            else:
                print(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} å¼‚å¸¸: {e}")
    
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰åŸºç¡€æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“ ä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œ python train.py å¼€å§‹è®­ç»ƒ")
        print("2. ä½¿ç”¨ nvidia-smi ç›‘æ§GPUä½¿ç”¨æƒ…å†µ")
        print("3. è®­ç»ƒå®Œæˆåä½¿ç”¨ python inference_triplet.py --interactive è¿›è¡Œæ¨ç†æµ‹è¯•")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç¯å¢ƒã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)