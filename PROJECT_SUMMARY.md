# ChatGLM-6B QLoRA ä¸‰å…ƒç»„æŠ½å–å¾®è°ƒé¡¹ç›®

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä½¿ç”¨QLoRAæŠ€æœ¯å¯¹ChatGLM-6Bæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå°†å…¶è®­ç»ƒæˆä¸“é—¨çš„ä¸‰å…ƒç»„æŠ½å–æ¨¡å‹ã€‚é¡¹ç›®åŒ…å«å®Œæ•´çš„è®­ç»ƒã€æ¨ç†å’Œè¯„ä¼°æµç¨‹ã€‚

## ğŸ¯ é¡¹ç›®ç‰¹ç‚¹

- **é«˜æ•ˆå¾®è°ƒ**: ä½¿ç”¨QLoRA (4-bité‡åŒ–) æŠ€æœ¯ï¼Œå¤§å¹…é™ä½æ˜¾å­˜éœ€æ±‚
- **ä¸“ä¸šä»»åŠ¡**: ä¸“é—¨é’ˆå¯¹ä¸‰å…ƒç»„æŠ½å–ä»»åŠ¡ä¼˜åŒ–
- **å®Œæ•´æµç¨‹**: åŒ…å«æ•°æ®ç”Ÿæˆã€è®­ç»ƒã€æ¨ç†ã€è¯„ä¼°çš„å®Œæ•´pipeline
- **æ˜“äºä½¿ç”¨**: æä¾›å¤šç§è¿è¡Œæ–¹å¼ (Shellè„šæœ¬ã€Pythonè„šæœ¬ã€é…ç½®æ–‡ä»¶)
- **é—®é¢˜ä¿®å¤**: è§£å†³äº†Windowsæ¢è¡Œç¬¦å’Œå‚æ•°è§£æç­‰å¸¸è§é—®é¢˜

## ğŸ“ é¡¹ç›®ç»“æ„

```
zjtz_work/
â”œâ”€â”€ src/                          # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ train_qlora.py           # QLoRAå¾®è°ƒä¸»ç¨‹åº
â”‚   â”œâ”€â”€ inference.py             # æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ evaluate.py              # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ generate_triplet_data.py # è®­ç»ƒæ•°æ®ç”Ÿæˆ
â”œâ”€â”€ scripts/                      # Shellè„šæœ¬
â”‚   â”œâ”€â”€ train.sh                 # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ inference.sh             # æ¨ç†è„šæœ¬
â”‚   â””â”€â”€ evaluate.sh              # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ data/                        # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ train_triplet.jsonl      # è®­ç»ƒæ•°æ® (903æ¡)
â”‚   â””â”€â”€ val_triplet.jsonl        # éªŒè¯æ•°æ® (101æ¡)
â”œâ”€â”€ config/                      # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ train_config.yaml        # è®­ç»ƒé…ç½®
â”œâ”€â”€ output/                      # è¾“å‡ºç›®å½•
â”œâ”€â”€ pure_python/                 # çº¯Pythonç‰ˆæœ¬
â”‚   â”œâ”€â”€ train_triplet.py         # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ inference_triplet.py     # æ¨ç†è„šæœ¬
â”‚   â””â”€â”€ evaluate_triplet.py      # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ demo_simple.py               # é¡¹ç›®æ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ requirements.txt             # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ TROUBLESHOOTING.md           # æ•…éšœæ’é™¤æŒ‡å—
â””â”€â”€ PROJECT_SUMMARY.md           # é¡¹ç›®æ€»ç»“ (æœ¬æ–‡ä»¶)
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æˆ–æ‰‹åŠ¨å®‰è£…æ ¸å¿ƒä¾èµ–
pip install torch transformers peft bitsandbytes datasets accelerate
```

### 2. æ•°æ®å‡†å¤‡
```bash
# ç”Ÿæˆè®­ç»ƒæ•°æ®
python src/generate_triplet_data.py
```

### 3. æ¨¡å‹è®­ç»ƒ

**æ–¹å¼1: ä½¿ç”¨Shellè„šæœ¬ (æ¨è)**
```bash
chmod +x scripts/train.sh
./scripts/train.sh
```

**æ–¹å¼2: ä½¿ç”¨çº¯Pythonè„šæœ¬**
```bash
python pure_python/train_triplet.py
```

**æ–¹å¼3: ç›´æ¥è¿è¡Œ**
```bash
python src/train_qlora.py \
    --model_name_or_path THUDM/chatglm-6b \
    --train_file data/train_triplet.jsonl \
    --validation_file data/val_triplet.jsonl \
    --output_dir output/chatglm-6b-triplet-qlora
```

### 4. æ¨¡å‹æ¨ç†
```bash
# ä½¿ç”¨Shellè„šæœ¬
./scripts/inference.sh

# æˆ–ä½¿ç”¨Pythonè„šæœ¬
python pure_python/inference_triplet.py
```

### 5. æ¨¡å‹è¯„ä¼°
```bash
# ä½¿ç”¨Shellè„šæœ¬
./scripts/evaluate.sh

# æˆ–ä½¿ç”¨Pythonè„šæœ¬
python pure_python/evaluate_triplet.py
```

## ğŸ”§ æŠ€æœ¯ç‰¹æ€§

### QLoRAé…ç½®
- **é‡åŒ–**: 4-bité‡åŒ– (NF4)
- **LoRAå‚æ•°**: r=8, alpha=32, dropout=0.1
- **ç›®æ ‡æ¨¡å—**: query_key_value, dense, dense_h_to_4h, dense_4h_to_h

### è®­ç»ƒé…ç½®
- **æ‰¹æ¬¡å¤§å°**: 4 (å¯è°ƒæ•´)
- **å­¦ä¹ ç‡**: 2e-4
- **è®­ç»ƒè½®æ•°**: 3
- **æ¢¯åº¦ç´¯ç§¯**: 4æ­¥
- **ä¼˜åŒ–å™¨**: AdamW
- **è°ƒåº¦å™¨**: çº¿æ€§é¢„çƒ­

### æ•°æ®æ ¼å¼
```json
{
    "instruction": "è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æŠ½å–ä¸‰å…ƒç»„ï¼Œæ ¼å¼ä¸º(ä¸»ä½“, å…³ç³», å®¢ä½“):",
    "input": "è‹¹æœå…¬å¸æ˜¯ä¸€å®¶ç¾å›½çš„ç§‘æŠ€å…¬å¸ï¼Œæ€»éƒ¨ä½äºåŠ åˆ©ç¦å°¼äºšå·åº“æ¯”è’‚è¯ºã€‚",
    "output": "(è‹¹æœå…¬å¸, æ˜¯, ç§‘æŠ€å…¬å¸)\n(è‹¹æœå…¬å¸, æ€»éƒ¨ä½äº, åŠ åˆ©ç¦å°¼äºšå·åº“æ¯”è’‚è¯º)\n(è‹¹æœå…¬å¸, å›½ç±, ç¾å›½)"
}
```

## ğŸ› ï¸ é—®é¢˜ä¿®å¤

### å·²è§£å†³çš„é—®é¢˜

1. **Windowsæ¢è¡Œç¬¦é—®é¢˜**
   - é”™è¯¯: `$'\r': command not found`
   - ä¿®å¤: é‡æ–°åˆ›å»ºShellè„šæœ¬ï¼Œä½¿ç”¨Unixæ¢è¡Œç¬¦

2. **å‚æ•°è§£æé—®é¢˜**
   - é”™è¯¯: `'THUDM/chatglm-6b\n'` åŒ…å«æ¢è¡Œç¬¦
   - ä¿®å¤: å¯¹æ‰€æœ‰å­—ç¬¦ä¸²å‚æ•°ä½¿ç”¨ `.strip()` æ–¹æ³•

3. **Shellè„šæœ¬é•¿è¡Œé—®é¢˜**
   - ä¿®å¤: ä½¿ç”¨å¤šè¡Œæ ¼å¼å’Œåæ–œæ è¿æ¥

4. **å‚æ•°ä¼ é€’é—®é¢˜**
   - ä¿®å¤: ä½¿ç”¨å¼•å·åŒ…å›´æ‰€æœ‰å˜é‡

### æ•…éšœæ’é™¤
è¯¦ç»†çš„æ•…éšœæ’é™¤æŒ‡å—è¯·å‚è€ƒ `TROUBLESHOOTING.md`

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### è®­ç»ƒæ•°æ®ç»Ÿè®¡
- **è®­ç»ƒé›†**: 903æ¡æ ·æœ¬
- **éªŒè¯é›†**: 101æ¡æ ·æœ¬
- **æ•°æ®ç±»å‹**: å¤šé¢†åŸŸä¸‰å…ƒç»„æŠ½å–ä»»åŠ¡

### ç¡¬ä»¶è¦æ±‚
- **æœ€ä½é…ç½®**: 12GB GPUæ˜¾å­˜
- **æ¨èé…ç½®**: 24GB+ GPUæ˜¾å­˜
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 50GB+ å¯ç”¨ç©ºé—´

### è®­ç»ƒæ—¶é—´ä¼°ç®—
- **12GB GPU**: ~4-6å°æ—¶ (batch_size=1)
- **24GB GPU**: ~2-3å°æ—¶ (batch_size=4)
- **40GB+ GPU**: ~1-2å°æ—¶ (batch_size=8)

## ğŸ® ä½¿ç”¨ç¤ºä¾‹

### è®­ç»ƒç¤ºä¾‹
```python
from src.train_qlora import main
import sys

# è®¾ç½®å‚æ•°
sys.argv = [
    'train_qlora.py',
    '--model_name_or_path', 'THUDM/chatglm-6b',
    '--train_file', 'data/train_triplet.jsonl',
    '--validation_file', 'data/val_triplet.jsonl',
    '--output_dir', 'output/my-triplet-model',
    '--num_train_epochs', '3'
]

# å¼€å§‹è®­ç»ƒ
main()
```

### æ¨ç†ç¤ºä¾‹
```python
from transformers import AutoTokenizer, AutoModel
from peft import PeftModel

# åŠ è½½æ¨¡å‹
base_model = AutoModel.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)
model = PeftModel.from_pretrained(base_model, "output/chatglm-6b-triplet-qlora")
tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm-6b", trust_remote_code=True)

# æ¨ç†
text = "è‹¹æœå…¬å¸æ˜¯ä¸€å®¶ç¾å›½çš„ç§‘æŠ€å…¬å¸ã€‚"
prompt = f"è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æŠ½å–ä¸‰å…ƒç»„ï¼Œæ ¼å¼ä¸º(ä¸»ä½“, å…³ç³», å®¢ä½“):\n{text}"

response, history = model.chat(tokenizer, prompt, history=[])
print(response)
```

## ğŸ“ˆ æ‰©å±•å»ºè®®

### æ•°æ®æ‰©å±•
1. å¢åŠ æ›´å¤šé¢†åŸŸçš„è®­ç»ƒæ•°æ®
2. ä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯
3. æ·»åŠ è´Ÿæ ·æœ¬è®­ç»ƒ

### æ¨¡å‹ä¼˜åŒ–
1. å°è¯•ä¸åŒçš„LoRAå‚æ•°ç»„åˆ
2. ä½¿ç”¨æ›´å¤§çš„åŸºç¡€æ¨¡å‹ (ChatGLM2-6B, ChatGLM3-6B)
3. å®éªŒä¸åŒçš„é‡åŒ–ç­–ç•¥

### åŠŸèƒ½æ‰©å±•
1. æ·»åŠ Webç•Œé¢
2. æ”¯æŒæ‰¹é‡å¤„ç†
3. æ·»åŠ æ¨¡å‹éƒ¨ç½²è„šæœ¬
4. é›†æˆåˆ°APIæœåŠ¡

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.2 (æœ€æ–°)
- âœ… ä¿®å¤Windowsæ¢è¡Œç¬¦é—®é¢˜
- âœ… ä¿®å¤å‚æ•°è§£æé—®é¢˜
- âœ… æ·»åŠ æ•…éšœæ’é™¤æŒ‡å—
- âœ… ä¼˜åŒ–Shellè„šæœ¬æ ¼å¼
- âœ… æ·»åŠ å‚æ•°éªŒè¯æµ‹è¯•

### v1.1
- âœ… æ·»åŠ çº¯Pythonè„šæœ¬ç‰ˆæœ¬
- âœ… åˆ›å»ºé¡¹ç›®æ¼”ç¤ºè„šæœ¬
- âœ… å®Œå–„æ–‡æ¡£å’ŒREADME

### v1.0
- âœ… å®ç°QLoRAå¾®è°ƒåŠŸèƒ½
- âœ… ç”Ÿæˆä¸‰å…ƒç»„è®­ç»ƒæ•°æ®
- âœ… åˆ›å»ºæ¨ç†å’Œè¯„ä¼°è„šæœ¬
- âœ… æ·»åŠ Shellè„šæœ¬æ”¯æŒ

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) - åŸºç¡€æ¨¡å‹
- [PEFT](https://github.com/huggingface/peft) - LoRAå®ç°
- [bitsandbytes](https://github.com/TimDettmers/bitsandbytes) - é‡åŒ–æ”¯æŒ
- [Transformers](https://github.com/huggingface/transformers) - æ¨¡å‹æ¡†æ¶

---

**é¡¹ç›®çŠ¶æ€**: âœ… å®Œæˆå¹¶å¯ç”¨  
**æœ€åæ›´æ–°**: 2025-10-27  
**ç»´æŠ¤è€…**: OpenHands AI Assistant