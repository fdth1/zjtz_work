#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ¨¡å‹è·¯å¾„æ£€æŸ¥è„šæœ¬
æ£€æŸ¥æœ¬åœ°ChatGLM-6Bæ¨¡å‹æ˜¯å¦å­˜åœ¨å¹¶å¯ç”¨
"""

import os
import sys
from glm_config import ProjectConfig

def check_model_path():
    """æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    pc = ProjectConfig()
    model_path = pc.pre_model
    
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹è·¯å¾„: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("1. ç¡®è®¤æ¨¡å‹å·²ä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„")
        print("2. æˆ–è€…ä¿®æ”¹ glm_config.py ä¸­çš„ self.pre_model è·¯å¾„")
        print("3. æˆ–è€…ä½¿ç”¨åœ¨çº¿æ¨¡å‹: self.pre_model = 'THUDM/chatglm-6b'")
        return False
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    required_files = [
        'config.json',
        'tokenizer.model',
        'pytorch_model.bin'
    ]
    
    missing_files = []
    for file in required_files:
        file_path = os.path.join(model_path, file)
        if not os.path.exists(file_path):
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†ç‰‡æ¨¡å‹æ–‡ä»¶
            if file == 'pytorch_model.bin':
                shard_files = [f for f in os.listdir(model_path) if f.startswith('pytorch_model-') and f.endswith('.bin')]
                if not shard_files:
                    missing_files.append(file)
            else:
                missing_files.append(file)
    
    if missing_files:
        print(f"âš ï¸ ç¼ºå°‘å…³é”®æ–‡ä»¶: {missing_files}")
        print("æ¨¡å‹å¯èƒ½ä¸å®Œæ•´ï¼Œå»ºè®®é‡æ–°ä¸‹è½½")
        return False
    
    print("âœ… æ¨¡å‹è·¯å¾„æ£€æŸ¥é€šè¿‡")
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    try:
        config_path = os.path.join(model_path, 'config.json')
        if os.path.exists(config_path):
            import json
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"ğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
            print(f"   - æ¨¡å‹åç§°: {config.get('name_or_path', 'ChatGLM-6B')}")
            print(f"   - è¯æ±‡è¡¨å¤§å°: {config.get('vocab_size', 'Unknown')}")
            print(f"   - éšè—å±‚å¤§å°: {config.get('hidden_size', 'Unknown')}")
            print(f"   - å±‚æ•°: {config.get('num_layers', 'Unknown')}")
    except Exception as e:
        print(f"âš ï¸ è¯»å–æ¨¡å‹é…ç½®æ—¶å‡ºé”™: {e}")
    
    return True

def check_disk_space():
    """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
    pc = ProjectConfig()
    model_path = pc.pre_model
    
    try:
        import shutil
        total, used, free = shutil.disk_usage(os.path.dirname(model_path))
        
        print(f"\nğŸ’¾ ç£ç›˜ç©ºé—´ä¿¡æ¯:")
        print(f"   - æ€»ç©ºé—´: {total // (1024**3):.1f} GB")
        print(f"   - å·²ä½¿ç”¨: {used // (1024**3):.1f} GB")
        print(f"   - å¯ç”¨ç©ºé—´: {free // (1024**3):.1f} GB")
        
        if free < 10 * 1024**3:  # å°äº10GB
            print("âš ï¸ å¯ç”¨ç£ç›˜ç©ºé—´ä¸è¶³10GBï¼Œå¯èƒ½å½±å“è®­ç»ƒ")
            return False
        
        return True
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ç£ç›˜ç©ºé—´æ—¶å‡ºé”™: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ChatGLM-6B æ¨¡å‹è·¯å¾„æ£€æŸ¥")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    model_ok = check_model_path()
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    disk_ok = check_disk_space()
    
    print("\n" + "=" * 50)
    if model_ok and disk_ok:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒï¼")
        return 0
    else:
        print("âŒ æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜åå†å¼€å§‹è®­ç»ƒ")
        return 1

if __name__ == "__main__":
    sys.exit(main())